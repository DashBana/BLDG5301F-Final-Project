{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLDG 5301 Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Timestamps in AHU 1 data:\n",
      "DatetimeIndex(['2017-12-31 01:00:00', '2017-12-31 02:00:00',\n",
      "               '2017-12-31 03:00:00', '2017-12-31 04:00:00',\n",
      "               '2017-12-31 05:00:00', '2017-12-31 06:00:00',\n",
      "               '2017-12-31 07:00:00', '2017-12-31 08:00:00',\n",
      "               '2017-12-31 09:00:00', '2017-12-31 10:00:00',\n",
      "               '2017-12-31 11:00:00', '2017-12-31 12:00:00',\n",
      "               '2017-12-31 13:00:00', '2017-12-31 14:00:00',\n",
      "               '2017-12-31 15:00:00', '2017-12-31 16:00:00',\n",
      "               '2017-12-31 17:00:00', '2017-12-31 18:00:00',\n",
      "               '2017-12-31 19:00:00', '2017-12-31 20:00:00',\n",
      "               '2017-12-31 21:00:00', '2017-12-31 22:00:00',\n",
      "               '2017-12-31 23:00:00'],\n",
      "              dtype='datetime64[ns]', name='Timestamp', freq=None)\n",
      "\n",
      "Missing Timestamps in AHU 2 data:\n",
      "DatetimeIndex(['2017-12-31 01:00:00', '2017-12-31 02:00:00',\n",
      "               '2017-12-31 03:00:00', '2017-12-31 04:00:00',\n",
      "               '2017-12-31 05:00:00', '2017-12-31 06:00:00',\n",
      "               '2017-12-31 07:00:00', '2017-12-31 08:00:00',\n",
      "               '2017-12-31 09:00:00', '2017-12-31 10:00:00',\n",
      "               '2017-12-31 11:00:00', '2017-12-31 12:00:00',\n",
      "               '2017-12-31 13:00:00', '2017-12-31 14:00:00',\n",
      "               '2017-12-31 15:00:00', '2017-12-31 16:00:00',\n",
      "               '2017-12-31 17:00:00', '2017-12-31 18:00:00',\n",
      "               '2017-12-31 19:00:00', '2017-12-31 20:00:00',\n",
      "               '2017-12-31 21:00:00', '2017-12-31 22:00:00',\n",
      "               '2017-12-31 23:00:00'],\n",
      "              dtype='datetime64[ns]', name='Timestamp', freq=None)\n",
      "\n",
      "Missing Timestamps in Energy Use data:\n",
      "DatetimeIndex(['2017-12-31 01:00:00', '2017-12-31 02:00:00',\n",
      "               '2017-12-31 03:00:00', '2017-12-31 04:00:00',\n",
      "               '2017-12-31 05:00:00', '2017-12-31 06:00:00',\n",
      "               '2017-12-31 07:00:00', '2017-12-31 08:00:00',\n",
      "               '2017-12-31 09:00:00', '2017-12-31 10:00:00',\n",
      "               '2017-12-31 11:00:00', '2017-12-31 12:00:00',\n",
      "               '2017-12-31 13:00:00', '2017-12-31 14:00:00',\n",
      "               '2017-12-31 15:00:00', '2017-12-31 16:00:00',\n",
      "               '2017-12-31 17:00:00', '2017-12-31 18:00:00',\n",
      "               '2017-12-31 19:00:00', '2017-12-31 20:00:00',\n",
      "               '2017-12-31 21:00:00', '2017-12-31 22:00:00',\n",
      "               '2017-12-31 23:00:00'],\n",
      "              dtype='datetime64[ns]', name='Timestamp', freq=None)\n"
     ]
    }
   ],
   "source": [
    "# Load all the provided CSV files\n",
    "weather_data_path = \"weather.csv\"\n",
    "ahu1_data_path = \"canal ahu 1.csv\"\n",
    "ahu2_data_path = \"canal ahu 2.csv\"\n",
    "energy_data_path = \"canal energy use.csv\"\n",
    "\n",
    "# Read the files into pandas DataFrames\n",
    "weather_data = pd.read_csv(weather_data_path)\n",
    "ahu1_data = pd.read_csv(ahu1_data_path)\n",
    "ahu2_data = pd.read_csv(ahu2_data_path)\n",
    "energy_data = pd.read_csv(energy_data_path)\n",
    "\n",
    "# Rename and convert timestamp columns to datetime format for all datasets\n",
    "weather_data.rename(columns={\"Unnamed: 0\": \"Timestamp\"}, inplace=True)\n",
    "weather_data[\"Timestamp\"] = pd.to_datetime(weather_data[\"Timestamp\"])\n",
    "\n",
    "ahu1_data.rename(columns={\"Unnamed: 0\": \"Timestamp\"}, inplace=True)\n",
    "ahu1_data[\"Timestamp\"] = pd.to_datetime(ahu1_data[\"Timestamp\"])\n",
    "\n",
    "ahu2_data.rename(columns={\"Unnamed: 0\": \"Timestamp\"}, inplace=True)\n",
    "ahu2_data[\"Timestamp\"] = pd.to_datetime(ahu2_data[\"Timestamp\"])\n",
    "\n",
    "energy_data.rename(columns={\"Unnamed: 0\": \"Timestamp\"}, inplace=True)\n",
    "energy_data[\"Timestamp\"] = pd.to_datetime(energy_data[\"Timestamp\"])\n",
    "\n",
    "# Set the Timestamp column as the index for all datasets\n",
    "weather_data.set_index(\"Timestamp\", inplace=True)\n",
    "ahu1_data.set_index(\"Timestamp\", inplace=True)\n",
    "ahu2_data.set_index(\"Timestamp\", inplace=True)\n",
    "energy_data.set_index(\"Timestamp\", inplace=True)\n",
    "\n",
    "# Identify missing timestamps for each dataset compared to the weather data\n",
    "missing_ahu1 = weather_data.index.difference(ahu1_data.index)\n",
    "missing_ahu2 = weather_data.index.difference(ahu2_data.index)\n",
    "missing_energy = weather_data.index.difference(energy_data.index)\n",
    "\n",
    "# Print the missing timestamps neatly\n",
    "print(\"Missing Timestamps in AHU 1 data:\")\n",
    "print(missing_ahu1)\n",
    "\n",
    "print(\"\\nMissing Timestamps in AHU 2 data:\")\n",
    "print(missing_ahu2)\n",
    "\n",
    "print(\"\\nMissing Timestamps in Energy Use data:\")\n",
    "print(missing_energy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Excel file created: Canal_Clean_Energy_Use.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the uploaded CSV file\n",
    "file_path = \"canal energy use.csv\"  # Replace with the actual path to your input file\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Rename the timestamp column for clarity\n",
    "# Assuming the timestamp column is unnamed, we rename it to 'Timestamp'\n",
    "data.rename(columns={\"Unnamed: 0\": \"Timestamp\"}, inplace=True)\n",
    "\n",
    "# Calculate the 'Total Chiller' column by summing 'Chiller 1' and 'Chiller 2'\n",
    "data[\"Total Chiller\"] = data[\"Chiller 1\"] + data[\"Chiller 2\"]\n",
    "\n",
    "# Calculate the 'Total AHU' column by summing 'AHU 1' and 'AHU 2'\n",
    "data[\"Total AHU\"] = data[\"AHU 1\"] + data[\"AHU 2\"]\n",
    "\n",
    "# Calculate the 'Total Plugs' column by summing all the plug columns\n",
    "plug_columns = [\"Plug 1\", \"Plug 2\", \"Plug 3\", \"Plug 4\", \"Plug 5\", \"Plug 6\"]\n",
    "data[\"Total Plugs\"] = data[plug_columns].sum(axis=1)\n",
    "\n",
    "# Calculate the 'Total Lighting' column by summing all the lighting columns\n",
    "lighting_columns = [\n",
    "    \"Lighting 1\",\n",
    "    \"Lighting 2\",\n",
    "    \"Lighting 3\",\n",
    "    \"Lighting 4\",\n",
    "    \"Lighting 5\",\n",
    "    \"Lighting 6\",\n",
    "]\n",
    "data[\"Total Lighting\"] = data[lighting_columns].sum(axis=1)\n",
    "\n",
    "# Create a new DataFrame with only the required columns\n",
    "cleaned_data = data[\n",
    "    [\"Timestamp\", \"Total Chiller\", \"Total AHU\", \"Total Plugs\", \"Total Lighting\"]\n",
    "]\n",
    "\n",
    "# Save the new data to an Excel file\n",
    "output_file_path = \"Canal_Clean_Energy_Use.xlsx\"  # Specify your desired output path\n",
    "cleaned_data.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"New Excel file created: {output_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
